# Awesome-LLM-Post-training-Papers
A curated list of papers and resources on post-training techniques for Large Language Models (LLMs), including continual learning, instruction tuning, reinforcement learning with human feedback (RLHF), tool use, alignment, safety, and more.

Post-training plays a critical role in adapting pretrained LLMs to downstream tasks, improving their reasoning, alignment, and usability in real-world applications. This repository aims to provide a structured and up-to-date reference for researchers, engineers, and enthusiasts in the field.

## Reinforcement Learning

## Tool-Integrated Reasoning
- **ART: Automatic multi‑step reasoning and tool‑use for LLMs** (Paranjape et al., 2023) — [arXiv](https://arxiv.org/abs/2303.09014)
- **ChatCoT: Tool‑Augmented Chain‑of‑Thought on Chat‑based LLMs** (Chen et al., EMNLP 2023) — [OpenReview](https://openreview.net/forum?id=4M4U3uC3Iy)
- **Augmented Language Models: a Survey** (2023) — [arXiv](https://arxiv.org/abs/2302.07842)
- **SciAgent: Tool‑augmented LMs for Scientific Reasoning** (EMNLP 2024) — [ACL Anthology](https://aclanthology.org/2024.emnlp‑main.880/)
- **Agentic Reasoning: Reasoning LLMs with Tools for Deep Research** (Wu et al., 2025) — [arXiv](https://arxiv.org/abs/2502.04644)
- **Self‑Training LLMs for Tool‑Use Without Demonstrations** (Luo et al., 2025) — [arXiv](https://arxiv.org/abs/2502.05867)
- **Advancing Tool‑Augmented LLMs: Error‑aware Inference Trees** (Chen et al., 2024) — [arXiv](https://arxiv.org/abs/2406.07115)
- **Efficient Tool Use with Chain‑of‑Abstraction** (Gao et al., 2024) — [arXiv](https://arxiv.org/abs/2401.17464)
- **IMP‑TIP: Improving Math Reasoning with Tool‑augmented Prompts** (2025) — [HuggingFace summary](https://huggingface.co/papers?q=tool‑augmented+LLMs)

