# Awesome-LLM-Post-training-Papers
A curated list of papers and resources on post-training techniques for Large Language Models (LLMs), including continual learning, instruction tuning, reinforcement learning with human feedback (RLHF), tool use, alignment, safety, and more.

Post-training plays a critical role in adapting pretrained LLMs to downstream tasks, improving their reasoning, alignment, and usability in real-world applications. This repository aims to provide a structured and up-to-date reference for researchers, engineers, and enthusiasts in the field.
## Survey
- **A Survey on Post‑training of Large Language Models** (Tie et al., Mar 2025) — [arXiv:2503.06072](https://arxiv.org/abs/2503.06072)
- **LLM Post‑Training: A Deep Dive into Reasoning Large Language Models** (Kumar et al., Feb 2025) — [arXiv:2502.21321](https://arxiv.org/abs/2502.21321)
- **Instruction Tuning for Large Language Models: A Survey** (2023) — [arXiv:2308.10792](https://arxiv.org/abs/2308.10792)
- **A Survey on Data Selection for LLM Instruction Tuning** (Wang et al., Jan 2024) — [OpenReview](https://openreview.net/forum?id=pHz5AgraIe)

## Reinforcement Learning

## Tool-Integrated Reasoning
- **ART: Automatic multi‑step reasoning and tool‑use for LLMs** (Paranjape et al., 2023) — [arXiv](https://arxiv.org/abs/2303.09014)
- **ChatCoT: Tool‑Augmented Chain‑of‑Thought on Chat‑based LLMs** (Chen et al., EMNLP 2023) — [OpenReview](https://openreview.net/forum?id=4M4U3uC3Iy)
- **Augmented Language Models: a Survey** (2023) — [arXiv](https://arxiv.org/abs/2302.07842)
- **SciAgent: Tool‑augmented LMs for Scientific Reasoning** (EMNLP 2024) — [ACL Anthology](https://aclanthology.org/2024.emnlp‑main.880/)
- **Agentic Reasoning: Reasoning LLMs with Tools for Deep Research** (Wu et al., 2025) — [arXiv](https://arxiv.org/abs/2502.04644)
- **Self‑Training LLMs for Tool‑Use Without Demonstrations** (Luo et al., 2025) — [arXiv](https://arxiv.org/abs/2502.05867)
- **Advancing Tool‑Augmented LLMs: Error‑aware Inference Trees** (Chen et al., 2024) — [arXiv](https://arxiv.org/abs/2406.07115)
- **Efficient Tool Use with Chain‑of‑Abstraction** (Gao et al., 2024) — [arXiv](https://arxiv.org/abs/2401.17464)
- **IMP‑TIP: Improving Math Reasoning with Tool‑augmented Prompts** (2025) — [HuggingFace summary](https://huggingface.co/papers?q=tool‑augmented+LLMs)

